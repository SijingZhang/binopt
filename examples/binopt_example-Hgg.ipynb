{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "%matplotlib inline\n",
    "plt.style.use('physics')\n",
    "\n",
    "plt.rcParams['axes.grid'       ]  = False\n",
    "plt.rcParams['xtick.labelsize' ]  = 14\n",
    "plt.rcParams['ytick.labelsize' ]  = 14\n",
    "plt.rcParams['axes.labelsize'  ]  = 14\n",
    "plt.rcParams['legend.fancybox' ]  = False\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import binopt\n",
    "\n",
    "from scipy import special as sp\n",
    "\n",
    "def divide( a, b ):\n",
    "    \"\"\" ignore / 0, div0( [-1, 0, 1], 0 ) -> [0, 0, 0] \"\"\"\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        c = np.true_divide( a, b )\n",
    "#         c[ ~ np.isfinite( c )] = 0\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../../data-driven/data/hgg-double-fake-trees-training-2017.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vbf_presel(data):\n",
    "    return (\n",
    "        (data[\"leadPho_PToM\"       ]> (1/3.0))&\n",
    "        (data[\"sublPho_PToM\"       ]> (1/4.0))&\n",
    "        (data[\"dijet_LeadJPt\"      ]> 30     )& \n",
    "        (data[\"dijet_SubJPt\"       ]> 20     )&\n",
    "        (data[\"dijet_Mjj\"          ]> 250    )&\n",
    "        (data[\"dipho_mass\"         ]> 100    )&\n",
    "        (data[\"dipho_mass\"         ]< 180    ))\n",
    "\n",
    "df = df[vbf_presel(df)]\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "clf = joblib.load('../../data-driven/notebooks/data-driven-bkg-GBC-training.pkl') \n",
    "\n",
    "def evaluate_sklearn(cls, vals, coef=1):\n",
    "    scale = 1.0 / cls.n_estimators\n",
    "    ret = np.zeros(vals.shape[0])\n",
    "\n",
    "    learning_rate = cls.learning_rate\n",
    "    for itree, t in enumerate(cls.estimators_[:, 0]):\n",
    "        r = t.predict(vals)\n",
    "        ret += r * scale\n",
    "    return 2.0/(1.0 + np.exp(-coef/learning_rate * ret)) - 1\n",
    "\n",
    "df['dijet_centrality_gg'] = np.exp(-4*(df.dijet_Zep/df.dijet_abs_dEta)**2)\n",
    "_dijetvar_ = [u'dijet_LeadJPt'  ,u'dijet_SubJPt', \n",
    "              u'dijet_abs_dEta' ,u'dijet_Mjj', \n",
    "              u'dijet_centrality_gg',u'dijet_dipho_dphi_trunc',\n",
    "              u'dijet_dphi'     ,u'dijet_minDRJetPho',\n",
    "              u'leadPho_PToM'   ,u'sublPho_PToM']\n",
    "\n",
    "df['dijet_bdt'] = evaluate_sklearn(clf,df[_dijetvar_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkgs = df[\n",
    "    (df['sample'] != 'data' ) & \n",
    "    (df['sample'] != 'qcd'  ) & \n",
    "    (df['sample'] != 'vbf'  ) &\n",
    "    (df['sample'] != 'gjet' ) & \n",
    "    (df['sample'] != 'zee'  )\n",
    "]\n",
    "df_sign = df[\n",
    "    (df['sample'] == 'vbf'  )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "plt.hist(df_bkgs.dijet_bdt,bins=100, range=[-1,1], \n",
    "         alpha=0.4, weights=df_bkgs.weight, \n",
    "         histtype='stepfilled',lw=1, normed=1)\n",
    "plt.hist(df_sign.dijet_bdt,bins=100, range=[-1,1], \n",
    "         alpha=0.4, weights=df_sign.weight, \n",
    "         histtype='stepfilled',lw=1, normed=1)\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(15)  # deterministic random data\n",
    "\n",
    "s = df_sign.dijet_bdt\n",
    "b = df_bkgs.dijet_bdt\n",
    "\n",
    "ms = df_sign.dipho_mass\n",
    "mb = df_bkgs.dipho_mass\n",
    "\n",
    "ws = df_sign.weight\n",
    "wb = df_bkgs.weight\n",
    "\n",
    "X = np.concatenate([s,b])\n",
    "Y = np.concatenate([np.ones(s.shape[0]), np.zeros(b.shape[0])])\n",
    "W = np.concatenate([ws,wb])\n",
    "M = np.concatenate([ms,mb])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "we_s, x = np.histogram(s, bins=50, range=[-1,1], weights=ws**2)\n",
    "we_b, _ = np.histogram(b, bins=50, range=[-1,1], weights=wb**2)\n",
    "\n",
    "he_s, _ = np.histogram(s, bins=50, range=[-1,1], weights=ws)\n",
    "he_b, _ = np.histogram(b, bins=50, range=[-1,1], weights=wb)\n",
    "\n",
    "x = np.array([(x[i] + x[i+1])/2.0  for i in range(0,len(x)-1)])\n",
    "plt.errorbar(x,he_s, yerr=np.sqrt(we_s), fmt='.', c='r', markersize=8, capthick=0)\n",
    "plt.errorbar(x,he_b, yerr=np.sqrt(we_b), fmt='.', c='b', markersize=8, capthick=0)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlim([-1,1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(binopt.optimize_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner = binopt.optimize_bin(nbins=3, range=[-1,1], \n",
    "                             drop_last_bin=True, fix_upper=True, \n",
    "                             fix_lower=False, use_kde_density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(binner.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner.fit(X, Y, sample_weights=W, method=\"Nelder-Mead\", breg=None, fom=\"AMS4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "we_s, x = np.histogram(s, bins=50, range=[-1,1], weights=ws**2)\n",
    "we_b, _ = np.histogram(b, bins=50, range=[-1,1], weights=wb**2)\n",
    "\n",
    "he_s, _ = np.histogram(s, bins=50, range=[-1,1], weights=ws)\n",
    "he_b, _ = np.histogram(b, bins=50, range=[-1,1], weights=wb)\n",
    "\n",
    "x = np.array([(x[i] + x[i+1])/2.0  for i in range(0,len(x)-1)])\n",
    "plt.errorbar(x,he_s, yerr=np.sqrt(we_s), fmt='.', c='r', markersize=8, capthick=0)\n",
    "plt.errorbar(x,he_b, yerr=np.sqrt(we_b), fmt='.', c='b', markersize=8, capthick=0)\n",
    "\n",
    "# plt.hist(s, bins=50, range=[0,1], weights=ws,\n",
    "#          color='red' ,histtype='step',lw=1.2, normed=0, label='signal')\n",
    "# plt.hist(b, bins=50, range=[0,1], weights=wb,\n",
    "#          color='blue',histtype='step',lw=1.2, normed=0, label='signal')\n",
    "\n",
    "for x in binner.result.x:\n",
    "    plt.axvline(x, ls='--', c = 'k')  \n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlim([-1,1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print binner.binned_score(binner.result.x)\n",
    "print binner.binned_stats(binner.result.x)[0]\n",
    "print binner.binned_stats(binner.result.x)[1]\n",
    "print binner.binned_stats(binner.result.x)[2]\n",
    "print binner.binned_stats(binner.result.x)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# binner.boundary_scan_2d()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation of the boundaries using $\\sigma_{\\rm eff}$ of signla peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as st\n",
    "\n",
    "def binned_score_mgg(bounds, X, y, W, mass, nsig=1):\n",
    "    \"\"\"\n",
    "    Input should contain a resonance of some sort.\n",
    "    \"\"\"\n",
    "    _bounds_ = np.sort(np.insert(bounds, [0, bounds.shape[0]], [binner.range]))\n",
    "    _cats_ = np.digitize(X, _bounds_)\n",
    "    _seff_ = np.zeros(_bounds_.shape[0])\n",
    "    _nums_ = np.zeros(_bounds_.shape[0])\n",
    "    _numb_ = np.zeros(_bounds_.shape[0])\n",
    "    _errb_ = np.zeros(_bounds_.shape[0])\n",
    "    frac = np.abs(norm.cdf(0, -nsig, 1) - norm.cdf(0, nsig, 1))\n",
    "    for cid in range(1,_bounds_.shape[0]):\n",
    "        max_, min_ = binopt.tools.weighted_quantile(\n",
    "            mass[(_cats_ == cid)& (y==1)],\n",
    "            [norm.cdf(0, -nsig, 1), norm.cdf(0, nsig, 1)],\n",
    "            sample_weight=W[(_cats_ == cid)& (y==1)])\n",
    "        \n",
    "        _seff_[cid] = np.abs(max_-min_)/2.0\n",
    "        _nums_[cid] = W[(_cats_ == cid) & (y==1)].sum()\n",
    "        _numb_[cid] = W[(_cats_ == cid) & (y==0)&\n",
    "                        (mass<max_)&(mass>min_) ].sum()*nsig*_seff_[cid]\n",
    "        _errb_[cid] = np.sqrt((W[(_cats_ == cid) & (y==0)&\n",
    "                        (mass<max_)&(mass>min_) ]**2).sum())\n",
    "#         print \"bakground [\",cid,\"] : \", _errb_[cid]\n",
    "#     return _errb_\n",
    "    return binner._fom_(_nums_, _numb_,_errb_, method=\"AMS4\")\n",
    "\n",
    "def binned_score_fit(bounds, X, y, W, mass, nsig=1):\n",
    "    \"\"\"\n",
    "    Input should contain a resonance of some sort.\n",
    "    \"\"\"\n",
    "    _bounds_ = np.sort(np.insert(bounds, [0, bounds.shape[0]], [binner.range]))\n",
    "    _cats_ = np.digitize(X, _bounds_)\n",
    "    _seff_ = np.zeros(_bounds_.shape[0])\n",
    "    _nums_ = np.zeros(_bounds_.shape[0])\n",
    "    _numb_ = np.zeros(_bounds_.shape[0])\n",
    "    _errb_ = np.zeros(_bounds_.shape[0])\n",
    "    frac = np.abs(norm.cdf(0, -nsig, 1) - norm.cdf(0, nsig, 1))\n",
    "    \n",
    "    for cid in range(1,_bounds_.shape[0]):\n",
    "        def _obj(x):\n",
    "            out = -np.sum(\n",
    "                W[(_cats_ == cid) & (y==0)]*st.expon(\n",
    "                    loc=100, scale=np.exp(x)\n",
    "                ).logpdf(mass[(_cats_ == cid) & (y==0)])\n",
    "            )\n",
    "            if np.isnan(out):\n",
    "                return 0\n",
    "            else:\n",
    "                return out\n",
    "        _fit = minimize(_obj, x0=[0.03], method='Powell')\n",
    "        min_, max_ = binopt.tools.weighted_quantile(\n",
    "            mass[(_cats_ == cid)& (y==1)],\n",
    "            [norm.cdf(0, -nsig, 1), norm.cdf(0, nsig, 1)],\n",
    "            sample_weight=W[(_cats_ == cid)& (y==1)])\n",
    "        \n",
    "        _seff_[cid] = np.abs(max_-min_)/2.0\n",
    "        _nums_[cid] = W[(_cats_ == cid) & (y==1)].sum()*frac\n",
    "        _numb_[cid] = np.abs(\n",
    "            st.expon(loc=100,scale=np.exp(_fit.x)).cdf(min_)-\n",
    "            st.expon(loc=100,scale=np.exp(_fit.x)).cdf(max_)\n",
    "        )\n",
    "        _errb_[cid] = np.sqrt((W[(_cats_ == cid) & (y==0)]**2).sum()*_numb_[cid])\n",
    "        _numb_[cid] *= W[(_cats_ == cid) & (y==0)].sum()\n",
    "    return binner._fom_(_nums_, _numb_,_errb_, method=\"AMS4\")\n",
    "\n",
    "def cost_fun_mgg(x):\n",
    "        \"\"\"Cost function.\"\"\"\n",
    "        z = None\n",
    "        z = binned_score_mgg(x, X, Y, W, M)\n",
    "        return -np.sqrt((z[1:]**2).sum())\n",
    "    \n",
    "def cost_fun_fit(x):\n",
    "        \"\"\"Cost function.\"\"\"\n",
    "        z = None\n",
    "        z = binned_score_fit(x, X, Y, W, M)\n",
    "        return -np.sqrt((z[1:]**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"count : \"\n",
    "print cost_fun_mgg(binner.result.x)\n",
    "print \"fit   : \"\n",
    "print cost_fun_fit(binner.result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_mgg_(x):\n",
    "    return cost_fun_mgg(np.array([x]))\n",
    "\n",
    "def cost_fit_(x):\n",
    "    return cost_fun_fit(np.array([x]))\n",
    "\n",
    "def cost_std_(x):\n",
    "    return binner.cost_fun(np.array([x]))\n",
    "cost_mgg_ = np.vectorize(cost_mgg_)\n",
    "cost_fit_ = np.vectorize(cost_fit_)\n",
    "cost_std_ = np.vectorize(cost_std_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "t = np.linspace(0,X.max(),100)\n",
    "plt.plot(t, cost_mgg_(t), 'b-')\n",
    "plt.plot(t, cost_fit_(t), 'r-')\n",
    "# plt.plot(t, cost_std_(t), 'g-')\n",
    "\n",
    "\n",
    "# plt.yscale('log')\n",
    "plt.xlim([0,1])\n",
    "# plt.ylim([-1.1,-0.7])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "t = np.linspace(0,X.max(),100)\n",
    "plt.plot(t, -cost_mgg_(t)/cost_mgg_(t).min(), 'b-', label = \"count in $\\sigma_{eff}$\")\n",
    "plt.plot(t, -cost_fit_(t)/cost_fit_(t).min(), 'r-', label = \"fit in $m_{\\gamma\\gamma}$\")\n",
    "plt.plot(t, -cost_std_(t)/cost_std_(t).min(), 'g-', label = \"count\")\n",
    "# plt.yscale('log')\n",
    "plt.xlim([0,1])\n",
    "# plt.ylim([-1.1,-0.7])\n",
    "plt.xlabel(\"$X_{cut}$\")\n",
    "plt.legend(loc = \"lower left\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
